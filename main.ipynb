{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727e82a0-24ed-4459-bd20-c86ff6f3bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibliotecas carregadas\n"
     ]
    }
   ],
   "source": [
    "#carregamento de bibliotecas\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import import_ipynb\n",
    "from controllers.utils.utils import mostrar_dataframe_interativo\n",
    "print(\"bibliotecas carregadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0156fa0-49fa-478a-b169-3d5eebc3d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configurações iniciais concluídas\n"
     ]
    }
   ],
   "source": [
    "#configuracoes e variaveis iniciais\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "iterations_count = 10;\n",
    "algoritms = ['knn', 'dt', 'svm', 'mlp']\n",
    "\n",
    "print(\"configurações iniciais concluídas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61129ae-f948-4b8f-9963-a186d0c4eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dados carregados: 2139 registros\n"
     ]
    }
   ],
   "source": [
    "#carregamendo dos dados\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "print(f\"dados carregados: {df['cid'].count()} registros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7280da9a-c607-40a2-90b5-2cc3ad0b590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL concluido\n"
     ]
    }
   ],
   "source": [
    "#ETL\n",
    "\n",
    "df = df.drop(columns=['pidnum']) #pidnum é a coluna de identificação do paciente, não tem significado para o treinamento\n",
    "\n",
    "print(\"ETL concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60b594a-fea3-4272-ac5e-fb35fdfcb0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fd5065de304f3aa71ce4cd4b1f4805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas até:', max=2139, min=10, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a12e70bc4074277ab6355d3ac223244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas por vez:', max=2139, min=5, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f60a4728acb4207ba30d4862ae12a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embaralhando as linhas do DataFrame\n",
    "\n",
    "df = df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "mostrar_dataframe_interativo(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4314a290-cbf0-49ea-8d64-75cb15f6d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variaveis independentes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d95c16fd0134e7e8d4154bbd6e4bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas até:', max=2139, min=10, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bef345636843b896b6220bf81444e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas por vez:', max=2139, min=5, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d823b899e90f4a21878894ce59acd6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variavel dependente (target)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb36d52316af4eb080d4243fb3264bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas até:', max=2139, min=10, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b230292f1f00401daa7589cdb13b0e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas por vez:', max=2139, min=5, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acaca4b04e6842698eb101c85721e872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extratificação \n",
    "\n",
    "X = df.drop(columns=['cid'])  # Variáveis independentes (todas as colunas menos a 'cid')\n",
    "y = df['cid']  # Variável dependente (alvo)\n",
    "print(\"Variaveis independentes\")\n",
    "mostrar_dataframe_interativo(X)\n",
    "print()\n",
    "print(\"Variavel dependente (target)\")\n",
    "mostrar_dataframe_interativo(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ea3291-6b6e-45a2-ba28-e03a3bcb90ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição original das classes em 'cid':\n",
      "cid\n",
      "0   0.756428\n",
      "1   0.243572\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes antes da divisão\n",
    "\n",
    "print(\"Distribuição original das classes em 'cid':\")\n",
    "print(y.value_counts(normalize=True))  # Proporção das classes antes da divisão\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2499c416-bb22-42e1-9e90-4da040762b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dados splitados\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, dividir em treino (50%) e restante (50% para validação + teste)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "print(\"dados splitados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f1e46b-a6a0-4917-bbb0-d08ac85f08a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição das classes no conjunto de treino (X_train):\n",
      "cid\n",
      "0   0.756782\n",
      "1   0.243218\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes no conjunto de treino\n",
    "\n",
    "print(\"Distribuição das classes no conjunto de treino (X_train):\")\n",
    "print(y_train.value_counts(normalize=True))  # Proporção das classes no treino\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "433cfad4-566f-41fc-bc57-1506552ac919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dados de validacao e teste splitados\n"
     ]
    }
   ],
   "source": [
    "# Segunda divisão: validação (25%) e teste (25%)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"dados de validacao e teste splitados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3598ab3-f785-4b7f-b569-3f03ce2e2c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição das classes no conjunto de validação (X_val):\n",
      "cid\n",
      "0   0.755140\n",
      "1   0.244860\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribuição das classes no conjunto de teste (X_test):\n",
      "cid\n",
      "0   0.757009\n",
      "1   0.242991\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes nos conjuntos de validação e teste\n",
    "\n",
    "print(\"Distribuição das classes no conjunto de validação (X_val):\")\n",
    "print(y_val.value_counts(normalize=True))  # Proporção das classes na validação\n",
    "print()\n",
    "\n",
    "print(\"Distribuição das classes no conjunto de teste (X_test):\")\n",
    "print(y_test.value_counts(normalize=True))  # Proporção das classes no teste\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50ca3bc-4d4d-478a-a720-64fa56227aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "função de classificacao e atualização de resultados criada\n"
     ]
    }
   ],
   "source": [
    "#funcao para rodar o classificar e armazenar os resultados\n",
    "\n",
    "def update_results(results,algoritm,iteration,y_val, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_val)  # Usando X_val e y_val para validação\n",
    "    iteration['accuracy'] = metrics.accuracy_score(y_val, y_pred)\n",
    "    iteration['confusion_matrix'] = metrics.confusion_matrix(y_val, y_pred).tolist()\n",
    "    iteration['elapsed_time'] = time.time() - iteration['start_time']\n",
    "    \n",
    "    results[algoritm]['iterations'].append(iteration)\n",
    "\n",
    "    # Atualizar melhores e piores índices e valores de acurácia e tempo\n",
    "    if not results[algoritm]['best_accuracy'] or iteration['accuracy'] > results[algoritm]['best_accuracy']['accuracy']:\n",
    "        results[algoritm]['best_accuracy'] = iteration\n",
    "\n",
    "    if not results[algoritm]['worst_accuracy'] or iteration['accuracy'] < results[algoritm]['worst_accuracy']['accuracy']:\n",
    "        results[algoritm]['worst_accuracy'] = iteration\n",
    "        \n",
    "    if not results['best_metrics']['best_accuracy'] or results['best_metrics']['best_accuracy']['accuracy'] < iteration['accuracy']: \n",
    "        results['best_metrics']['best_accuracy'] = dict(iteration)\n",
    "        results['best_metrics']['best_accuracy']['algoritm'] = algoritm\n",
    "    \n",
    "    if not results['worst_metrics']['worst_accuracy'] or results['worst_metrics']['worst_accuracy']['accuracy'] > iteration['accuracy']: \n",
    "        results['worst_metrics']['worst_accuracy'] = dict(iteration)\n",
    "        results['worst_metrics']['worst_accuracy']['algoritm'] = algoritm\n",
    "\n",
    "    if not results[algoritm]['best_time'] or iteration['elapsed_time'] < results[algoritm]['best_time']['elapsed_time']:\n",
    "        results[algoritm]['best_time'] = iteration\n",
    "\n",
    "    if not results[algoritm]['worst_time'] or iteration['elapsed_time'] > results[algoritm]['worst_time']['elapsed_time']:\n",
    "        results[algoritm]['worst_time'] = iteration\n",
    "        \n",
    "    if not results['best_metrics']['best_time'] or results['best_metrics']['best_time']['elapsed_time'] > iteration['elapsed_time']: \n",
    "        results['best_metrics']['best_time'] = dict(iteration)\n",
    "        results['best_metrics']['best_time']['algoritm'] = algoritm\n",
    "    \n",
    "    if not results['worst_metrics']['worst_time'] or results['worst_metrics']['worst_time']['elapsed_time'] < iteration['elapsed_time']: \n",
    "        results['worst_metrics']['worst_time'] = dict(iteration)\n",
    "        results['worst_metrics']['worst_time']['algoritm'] = algoritm\n",
    "\n",
    "print(\"função de classificacao e atualização de resultados criada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd6c6c8-a4b0-4b15-a0cc-9b2ce6b47bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicionario de resultados de validação e teste criado\n"
     ]
    }
   ],
   "source": [
    "# Dicionários para armazenar resultados de validação e teste\n",
    "\n",
    "validation_results = {\n",
    "    'iterations':0,\n",
    "    'start_time':time.time(),\n",
    "    'elapsed_time':0,\n",
    "    'best_metrics': {'best_accuracy': None, 'best_time': None},\n",
    "    'worst_metrics': {'worst_accuracy': None, 'worst_time': None}\n",
    "}\n",
    "\n",
    "test_results = {\n",
    "    'iterations':0,\n",
    "    'start_time':time.time(),\n",
    "    'elapsed_time':0,\n",
    "    'best_metrics': {'best_accuracy': None, 'best_time': None},\n",
    "    'worst_metrics': {'worst_accuracy': None, 'worst_time': None}\n",
    "}\n",
    "\n",
    "for alg in algoritms:\n",
    "    validation_results[alg] = {'iterations': [], 'best_accuracy': None, 'best_time': None, 'worst_accuracy': None, 'worst_time': None}\n",
    "    test_results[alg] = {'iterations': [], 'best_accuracy': None, 'best_time': None, 'worst_accuracy': None, 'worst_time': None}\n",
    "\n",
    "print(\"dicionario de resultados de validação e teste criado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f84e0aa-6413-4479-afca-9661b3a54144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop de validacao concluido\n"
     ]
    }
   ],
   "source": [
    "#LOOP DE EXECUSSÕES DE VALIDAÇÃO (LOOP 1)\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    \n",
    "    ### KNN Classifier\n",
    "    knn_iteration = {        \n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'k':np.random.randint(1, 21), # Valor de K aleatório entre 1 e 20\n",
    "            'weights': np.random.choice(['uniform', 'distance']) # Pesos aleatórios\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=knn_iteration['parameters']['k'], weights=knn_iteration['parameters']['weights'])\n",
    "    update_results(validation_results,'knn',knn_iteration,y_val,knn_clf)\n",
    "    \n",
    "    ### Decision Tree Classifier\n",
    "    dt_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'max_depth': np.random.randint(1, 11),  # Aleatório entre 1 e 10\n",
    "            'min_samples_split': np.random.randint(2, 11),  # Aleatório entre 2 e 10\n",
    "            'criterion': np.random.choice(['gini', 'entropy'])  # Critério aleatório\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=dt_iteration['parameters']['max_depth'], min_samples_split=dt_iteration['parameters']['min_samples_split'], criterion=dt_iteration['parameters']['criterion'])\n",
    "    update_results(validation_results,'dt',dt_iteration,y_val,dt_clf)\n",
    "\n",
    "    ### SVM Classifier\n",
    "    svm_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'C': np.random.uniform(0.1, 1.0),  # Valor de erro aleatório (C)\n",
    "            'kernel': np.random.choice(['rbf', 'poly'])  # Tipo de Kernel aleatório (linear excluido por ser mais demorado)\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    svm_clf = SVC(C=svm_iteration['parameters']['C'], kernel=svm_iteration['parameters']['kernel'])\n",
    "    update_results(validation_results,'svm',svm_iteration,y_val,svm_clf) \n",
    "\n",
    "    ### MLP Classifier\n",
    "    mlp_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'epochs': np.random.randint(50, 301),  # Número de épocas aleatório entre 50 e 300\n",
    "            'learning_rate': np.random.uniform(0.001, 0.1),  # Taxa de aprendizagem aleatória\n",
    "            'hidden_layers': np.random.randint(1, 6),  # Número de camadas escondidas aleatório entre 1 e 5\n",
    "            'activation': np.random.choice(['identity', 'logistic', 'tanh', 'relu']),  # Função de ativação aleatória\n",
    "            #'max_iter': 100,  # Aumenta o limite de iterações\n",
    "            #'tol': 1e-3  # Tolerância um pouco maior para convergência\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(mlp_iteration['parameters']['hidden_layers'],), max_iter=mlp_iteration['parameters']['epochs'], learning_rate_init=mlp_iteration['parameters']['learning_rate'], activation=mlp_iteration['parameters']['activation'])\n",
    "    update_results(validation_results,'mlp',mlp_iteration,y_val,mlp_clf) \n",
    "\n",
    "    validation_results['iterations'] += 1\n",
    "\n",
    "validation_results['elapsed_time'] = time.time() - validation_results['start_time']\n",
    "\n",
    "print(\"loop de validacao concluido\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d68481-3275-4a5b-9f67-1f660fa4f2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostrar json ? (descomente)\n"
     ]
    }
   ],
   "source": [
    "# Exibir resultados de validação\n",
    "print(\"mostrar json ? (descomente)\")\n",
    "#print(json.dumps(validation_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fc59124-63a3-49b0-a11c-085fe725f32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Medias de acuracias na validação\n",
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.833645 0.846729 0.829907 0.755140\n",
      "1          2 0.826168 0.846729 0.835514 0.829907\n",
      "2          3 0.826168 0.846729 0.833645 0.755140\n",
      "3          4 0.831776 0.846729 0.829907 0.818692\n",
      "4          5 0.831776 0.813084 0.814953 0.755140\n",
      "5          6 0.820561 0.854206 0.837383 0.818692\n",
      "6          7 0.779439 0.857944 0.833645 0.755140\n",
      "7          8 0.820561 0.839252 0.831776 0.755140\n",
      "8          9 0.831776 0.856075 0.814953 0.816822\n",
      "9         10 0.833645 0.837383 0.814953 0.755140\n",
      "10       AVG 0.823551 0.844486 0.827664 0.781495\n",
      "\n",
      "Medias de tempos na validação\n",
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.137356 0.000000 0.104475 0.033367\n",
      "1          2 0.061719 0.010288 0.072263 0.227944\n",
      "2          3 0.053924 0.000997 0.061826 0.049368\n",
      "3          4 0.086540 0.016787 0.041299 0.061871\n",
      "4          5 0.089457 0.002505 0.056590 0.022087\n",
      "5          6 0.099579 0.011968 0.027512 0.068731\n",
      "6          7 0.104402 0.002545 0.042461 0.025676\n",
      "7          8 0.086121 0.009011 0.075869 0.026162\n",
      "8          9 0.092751 0.000000 0.050176 0.069040\n",
      "9         10 0.097078 0.012095 0.052627 0.041326\n",
      "10       AVG 0.090893 0.006620 0.058510 0.062557\n"
     ]
    }
   ],
   "source": [
    "#tabulação dos resultados da validação e calculo das medias\n",
    "\n",
    "validation_accuracy_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "validation_time_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "validation_accuracy_avgs = {}\n",
    "validation_time_avgs = {}\n",
    "\n",
    "for alg in algoritms:\n",
    "    validation_accuracy_table[alg] = []\n",
    "    validation_accuracy_avgs[alg] = 0\n",
    "    validation_time_table[alg] = []\n",
    "    validation_time_avgs[alg] = 0\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    validation_accuracy_table['repetição'].append(i+1)  \n",
    "    validation_time_table['repetição'].append(i+1)  \n",
    "    for alg in algoritms:\n",
    "        if len(validation_results[alg]['iterations']) > 0:\n",
    "            validation_accuracy_table[alg].append(validation_results[alg]['iterations'][i]['accuracy'])\n",
    "            validation_accuracy_avgs[alg] += validation_results[alg]['iterations'][i]['accuracy']\n",
    "            validation_time_table[alg].append(validation_results[alg]['iterations'][i]['elapsed_time'])\n",
    "            validation_time_avgs[alg] += validation_results[alg]['iterations'][i]['elapsed_time']\n",
    "        else:\n",
    "            validation_accuracy_table[alg].append(0)\n",
    "            validation_time_table[alg].append(float('inf'))\n",
    "\n",
    "validation_accuracy_table['repetição'].append('AVG')\n",
    "validation_time_table['repetição'].append('AVG')\n",
    "for alg in algoritms:\n",
    "    validation_accuracy_avgs[alg] = validation_accuracy_avgs[alg] / iterations_count\n",
    "    validation_time_avgs[alg] = validation_time_avgs[alg] / iterations_count\n",
    "    validation_accuracy_table[alg].append(validation_accuracy_avgs[alg])\n",
    "    validation_time_table[alg].append(validation_time_avgs[alg])\n",
    "\n",
    "validation_accuracy_table = pd.DataFrame(validation_accuracy_table)\n",
    "validation_time_table = pd.DataFrame(validation_time_table)\n",
    "\n",
    "print()\n",
    "print(\"Medias de acuracias na validação\")\n",
    "print(validation_accuracy_table)\n",
    "#mostrar_dataframe_interativo(validation_accuracy_table,min(len(validation_accuracy_table),iterations_count)+1,min(len(validation_accuracy_table),iterations_count)+1)\n",
    "print()\n",
    "print(\"Medias de tempos na validação\")\n",
    "print(validation_time_table)\n",
    "#mostrar_dataframe_interativo(validation_time_table,min(len(validation_time_table),iterations_count)+1,min(len(validation_time_table),iterations_count)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b474e5-d276-4b01-8039-2bc9a685f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop de validacao concluido\n"
     ]
    }
   ],
   "source": [
    "#LOOP DE EXECUSSÕES DE TESTE (LOOP 2)\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    \n",
    "    ### KNN Classifier\n",
    "    knn_iteration = {        \n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['knn']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=knn_iteration['parameters']['k'], weights=knn_iteration['parameters']['weights'])\n",
    "    update_results(test_results,'knn',knn_iteration,y_val,knn_clf)\n",
    "    \n",
    "    ### Decision Tree Classifier\n",
    "    dt_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['dt']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=dt_iteration['parameters']['max_depth'], min_samples_split=dt_iteration['parameters']['min_samples_split'], criterion=dt_iteration['parameters']['criterion'])\n",
    "    update_results(test_results,'dt',dt_iteration,y_val,dt_clf)\n",
    "\n",
    "    ### SVM Classifier\n",
    "    svm_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['svm']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    svm_clf = SVC(C=svm_iteration['parameters']['C'], kernel=svm_iteration['parameters']['kernel'])\n",
    "    update_results(test_results,'svm',svm_iteration,y_val,svm_clf)\n",
    "\n",
    "    ### MLP Classifier\n",
    "    mlp_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['mlp']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(mlp_iteration['parameters']['hidden_layers'],), max_iter=mlp_iteration['parameters']['epochs'], learning_rate_init=mlp_iteration['parameters']['learning_rate'], activation=mlp_iteration['parameters']['activation'])\n",
    "    update_results(test_results,'mlp',mlp_iteration,y_val,mlp_clf) \n",
    "\n",
    "    test_results['iterations'] += 1\n",
    "\n",
    "test_results['elapsed_time'] = time.time() - test_results['start_time']\n",
    "\n",
    "print(\"loop de testes concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51193a53-d49b-4750-8704-524aa91fa32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostrar json ? (descomente)\n"
     ]
    }
   ],
   "source": [
    "# Exibir resultados de teste\n",
    "print(\"mostrar json ? (descomente)\")\n",
    "#print(json.dumps(test_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b1fa07-f85c-439d-a61e-06902128180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Medias de acuracias no teste\n",
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.833645 0.863551 0.837383 0.755140\n",
      "1          2 0.833645 0.869159 0.837383 0.766355\n",
      "2          3 0.833645 0.859813 0.837383 0.755140\n",
      "3          4 0.833645 0.857944 0.837383 0.828037\n",
      "4          5 0.833645 0.859813 0.837383 0.796262\n",
      "5          6 0.833645 0.865421 0.837383 0.755140\n",
      "6          7 0.833645 0.861682 0.837383 0.798131\n",
      "7          8 0.833645 0.863551 0.837383 0.758879\n",
      "8          9 0.833645 0.856075 0.837383 0.755140\n",
      "9         10 0.833645 0.865421 0.837383 0.755140\n",
      "10       AVG 0.833645 0.862243 0.837383 0.772336\n",
      "\n",
      "Medias de tempos no teste\n",
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.117727 0.025703 0.077212 0.217719\n",
      "1          2 0.091113 0.008508 0.086956 0.054049\n",
      "2          3 0.085105 0.025288 0.057829 0.095766\n",
      "3          4 0.086436 0.016756 0.070159 0.147305\n",
      "4          5 0.089313 0.023556 0.068780 0.452517\n",
      "5          6 0.086276 0.020243 0.075871 0.070005\n",
      "6          7 0.094466 0.022931 0.076268 0.094008\n",
      "7          8 0.079304 0.017653 0.079991 0.448236\n",
      "8          9 0.083773 0.016726 0.075685 0.111742\n",
      "9         10 0.085297 0.015848 0.068105 0.133353\n",
      "10       AVG 0.089881 0.019321 0.073686 0.182470\n"
     ]
    }
   ],
   "source": [
    "#tabulação dos resultados da teste e calculo das medias\n",
    "\n",
    "test_accuracy_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "test_time_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "test_accuracy_avgs = {}\n",
    "test_time_avgs = {}\n",
    "\n",
    "for alg in algoritms:\n",
    "    test_accuracy_table[alg] = []\n",
    "    test_accuracy_avgs[alg] = 0\n",
    "    test_time_table[alg] = []\n",
    "    test_time_avgs[alg] = 0\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    test_accuracy_table['repetição'].append(i+1)  \n",
    "    test_time_table['repetição'].append(i+1)  \n",
    "    for alg in algoritms:\n",
    "        if len(test_results[alg]['iterations']) > 0:\n",
    "            test_accuracy_table[alg].append(test_results[alg]['iterations'][i]['accuracy'])\n",
    "            test_accuracy_avgs[alg] += test_results[alg]['iterations'][i]['accuracy']\n",
    "            test_time_table[alg].append(test_results[alg]['iterations'][i]['elapsed_time'])\n",
    "            test_time_avgs[alg] += test_results[alg]['iterations'][i]['elapsed_time']\n",
    "        else:\n",
    "            test_accuracy_table[alg].append(0)\n",
    "            test_time_table[alg].append(float('inf'))\n",
    "\n",
    "test_accuracy_table['repetição'].append('AVG')\n",
    "test_time_table['repetição'].append('AVG')\n",
    "\n",
    "for alg in algoritms:\n",
    "    test_accuracy_avgs[alg] = test_accuracy_avgs[alg] / iterations_count\n",
    "    test_time_avgs[alg] = test_time_avgs[alg] / iterations_count\n",
    "    test_accuracy_table[alg].append(test_accuracy_avgs[alg])\n",
    "    test_time_table[alg].append(test_time_avgs[alg])\n",
    "\n",
    "test_accuracy_table = pd.DataFrame(test_accuracy_table)\n",
    "test_time_table = pd.DataFrame(test_time_table)\n",
    "\n",
    "print()\n",
    "print(\"Medias de acuracias no teste\")\n",
    "print(test_accuracy_table)\n",
    "#mostrar_dataframe_interativo(test_accuracy_table,min(len(test_accuracy_table),iterations_count)+1,min(len(test_accuracy_table),iterations_count)+1)\n",
    "print()\n",
    "print(\"Medias de tempos no teste\")\n",
    "print(test_time_table)\n",
    "#mostrar_dataframe_interativo(test_time_table,min(len(test_time_table),iterations_count)+1,min(len(test_time_table),iterations_count)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511ff826-0933-4cd4-8223-7a7180435b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando testes de performance...\n"
     ]
    }
   ],
   "source": [
    "#APLICAR OS TESTES DE PERFORMANCE AQUI\n",
    "\n",
    "print(\"Aplicando testes de performance...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
