{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727e82a0-24ed-4459-bd20-c86ff6f3bb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>bibliotecas carregadas<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#carregamento de bibliotecas\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import import_ipynb\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import mannwhitneyu\n",
    "import itertools\n",
    "from controllers.utils.utils import show_title, mostrar_dataframe_interativo\n",
    "\n",
    "show_title(\"bibliotecas carregadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0156fa0-49fa-478a-b169-3d5eebc3d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>configurações iniciais concluídas<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#configuracoes e variaveis iniciais\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "iterations_count = 10;\n",
    "algoritms = ['knn', 'dt', 'svm', 'mlp']\n",
    "\n",
    "show_title(\"configurações iniciais concluídas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d61129ae-f948-4b8f-9963-a186d0c4eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>dados carregados: 2139 registros<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#carregamendo dos dados\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "show_title(f\"dados carregados: {df['cid'].count()} registros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7280da9a-c607-40a2-90b5-2cc3ad0b590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coluna zprior excluida\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>ETL concluido<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ETL\n",
    "\n",
    "df = df.drop(columns=['pidnum']) #pidnum é a coluna de identificação do paciente, não tem significado para o treinamento\n",
    "\n",
    "# Identifica e remove colunas com valores iguais em todas as linhas\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 1:        \n",
    "        df = df.drop(columns=[col])\n",
    "        print(f\"coluna {col} excluida\")\n",
    "        \n",
    "show_title(\"ETL concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f60b594a-fea3-4272-ac5e-fb35fdfcb0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Dados embaralhados<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de09427457b644c48f09f1fc75459945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas até:', max=2139, min=10, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ca0089ee51468baee3a41368e8ae8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas por vez:', max=2139, min=5, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faecb3c6490450c81460a12d0e0080e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embaralhando as linhas do DataFrame\n",
    "\n",
    "df = df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "show_title(\"Dados embaralhados\")\n",
    "mostrar_dataframe_interativo(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4314a290-cbf0-49ea-8d64-75cb15f6d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Variaveis independentes<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dabb6e94764b9ba5c1d979a2601d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas até:', max=2139, min=10, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfc073f939d410599887223678d8602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas por vez:', max=2139, min=5, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2b4892be4040f39cfaedff0a547973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extratificação \n",
    "\n",
    "X = df.drop(columns=['cid'])  # Variáveis independentes (todas as colunas menos a 'cid')\n",
    "y = df['cid']  # Variável dependente (alvo)\n",
    "\n",
    "show_title(\"Variaveis independentes\")\n",
    "mostrar_dataframe_interativo(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "273f56de-2f63-410b-bf2a-7f3bdf51d240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Variavel dependente (target)<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de914d74d9a64c3e9c433b5d81e40211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas até:', max=2139, min=10, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1960b709c3204a37abce6d93fdeea51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Linhas por vez:', max=2139, min=5, step=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2ad39ec995457aab157fe6edaaa241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_title(\"Variavel dependente (target)\")\n",
    "mostrar_dataframe_interativo(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ea3291-6b6e-45a2-ba28-e03a3bcb90ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Distribuição original das classes em 'cid':<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid\n",
      "0   0.756428\n",
      "1   0.243572\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes antes da divisão\n",
    "\n",
    "show_title(\"Distribuição original das classes em 'cid':\")\n",
    "print(y.value_counts(normalize=True))  # Proporção das classes antes da divisão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2499c416-bb22-42e1-9e90-4da040762b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>dados splitados para treinamento<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primeiro, dividir em treino (50%) e restante (50% para validação + teste)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "show_title(\"dados splitados para treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7f1e46b-a6a0-4917-bbb0-d08ac85f08a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Distribuição das classes no conjunto de treino (y_train):<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid\n",
      "0   0.756782\n",
      "1   0.243218\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes no conjunto de treino\n",
    "\n",
    "show_title(\"Distribuição das classes no conjunto de treino (y_train):\")\n",
    "print(y_train.value_counts(normalize=True))  # Proporção das classes no treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "433cfad4-566f-41fc-bc57-1506552ac919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>dados de validacao e teste splitados<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Segunda divisão: validação (25%) e teste (25%)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "show_title(\"dados de validacao e teste splitados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3598ab3-f785-4b7f-b569-3f03ce2e2c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Distribuição das classes no conjunto de validação (y_val):<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid\n",
      "0   0.755140\n",
      "1   0.244860\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Distribuição das classes no conjunto de teste (y_test):<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid\n",
      "0   0.757009\n",
      "1   0.242991\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes nos conjuntos de validação e teste\n",
    "\n",
    "show_title(\"Distribuição das classes no conjunto de validação (y_val):\")\n",
    "print(y_val.value_counts(normalize=True))  # Proporção das classes na validação\n",
    "print()\n",
    "\n",
    "show_title(\"Distribuição das classes no conjunto de teste (y_test):\")\n",
    "print(y_test.value_counts(normalize=True))  # Proporção das classes no teste\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e50ca3bc-4d4d-478a-a720-64fa56227aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>função de classificacao e atualização de resultados criada<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#funcao para rodar o classificar e armazenar os resultados\n",
    "\n",
    "def update_results(results,algoritm,iteration,y_val, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_val)  # Usando X_val e y_val para validação\n",
    "    iteration['accuracy'] = metrics.accuracy_score(y_val, y_pred)\n",
    "    iteration['confusion_matrix'] = metrics.confusion_matrix(y_val, y_pred).tolist()\n",
    "    iteration['elapsed_time'] = time.time() - iteration['start_time']\n",
    "    \n",
    "    results[algoritm]['iterations'].append(iteration)\n",
    "\n",
    "    # Atualizar melhores e piores índices e valores de acurácia e tempo\n",
    "    if not results[algoritm]['best_accuracy'] or iteration['accuracy'] > results[algoritm]['best_accuracy']['accuracy']:\n",
    "        results[algoritm]['best_accuracy'] = iteration\n",
    "\n",
    "    if not results[algoritm]['worst_accuracy'] or iteration['accuracy'] < results[algoritm]['worst_accuracy']['accuracy']:\n",
    "        results[algoritm]['worst_accuracy'] = iteration\n",
    "        \n",
    "    if not results['best_metrics']['best_accuracy'] or results['best_metrics']['best_accuracy']['accuracy'] < iteration['accuracy']: \n",
    "        results['best_metrics']['best_accuracy'] = dict(iteration)\n",
    "        results['best_metrics']['best_accuracy']['algoritm'] = algoritm\n",
    "    \n",
    "    if not results['worst_metrics']['worst_accuracy'] or results['worst_metrics']['worst_accuracy']['accuracy'] > iteration['accuracy']: \n",
    "        results['worst_metrics']['worst_accuracy'] = dict(iteration)\n",
    "        results['worst_metrics']['worst_accuracy']['algoritm'] = algoritm\n",
    "\n",
    "    if not results[algoritm]['best_time'] or iteration['elapsed_time'] < results[algoritm]['best_time']['elapsed_time']:\n",
    "        results[algoritm]['best_time'] = iteration\n",
    "\n",
    "    if not results[algoritm]['worst_time'] or iteration['elapsed_time'] > results[algoritm]['worst_time']['elapsed_time']:\n",
    "        results[algoritm]['worst_time'] = iteration\n",
    "        \n",
    "    if not results['best_metrics']['best_time'] or results['best_metrics']['best_time']['elapsed_time'] > iteration['elapsed_time']: \n",
    "        results['best_metrics']['best_time'] = dict(iteration)\n",
    "        results['best_metrics']['best_time']['algoritm'] = algoritm\n",
    "    \n",
    "    if not results['worst_metrics']['worst_time'] or results['worst_metrics']['worst_time']['elapsed_time'] < iteration['elapsed_time']: \n",
    "        results['worst_metrics']['worst_time'] = dict(iteration)\n",
    "        results['worst_metrics']['worst_time']['algoritm'] = algoritm\n",
    "\n",
    "show_title(\"função de classificacao e atualização de resultados criada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cd6c6c8-a4b0-4b15-a0cc-9b2ce6b47bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>dicionario de resultados de validação e teste criado<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dicionários para armazenar resultados de validação e teste\n",
    "\n",
    "validation_results = {\n",
    "    'iterations':0,\n",
    "    'start_time':time.time(),\n",
    "    'elapsed_time':0,\n",
    "    'best_metrics': {'best_accuracy': None, 'best_time': None},\n",
    "    'worst_metrics': {'worst_accuracy': None, 'worst_time': None}\n",
    "}\n",
    "\n",
    "test_results = {\n",
    "    'iterations':0,\n",
    "    'start_time':time.time(),\n",
    "    'elapsed_time':0,\n",
    "    'best_metrics': {'best_accuracy': None, 'best_time': None},\n",
    "    'worst_metrics': {'worst_accuracy': None, 'worst_time': None}\n",
    "}\n",
    "\n",
    "for alg in algoritms:\n",
    "    validation_results[alg] = {'iterations': [], 'best_accuracy': None, 'best_time': None, 'worst_accuracy': None, 'worst_time': None}\n",
    "    test_results[alg] = {'iterations': [], 'best_accuracy': None, 'best_time': None, 'worst_accuracy': None, 'worst_time': None}\n",
    "\n",
    "show_title(\"dicionario de resultados de validação e teste criado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f84e0aa-6413-4479-afca-9661b3a54144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>loop de validacao concluido<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOOP DE EXECUSSÕES DE VALIDAÇÃO (LOOP 1)\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    \n",
    "    ### KNN Classifier\n",
    "    knn_iteration = {        \n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'k':np.random.randint(1, 20), # Valor de K aleatório \n",
    "            'weights': np.random.choice(['uniform', 'distance']) # Pesos aleatórios\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=knn_iteration['parameters']['k'], weights=knn_iteration['parameters']['weights'])\n",
    "    update_results(validation_results,'knn',knn_iteration,y_val,knn_clf)\n",
    "    \n",
    "    ### Decision Tree Classifier\n",
    "    dt_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'max_depth': np.random.randint(1, 100),  # Aleatório entre \n",
    "            'min_samples_split': np.random.randint(2, 30),  # Aleatório entre 2 e 10 (influencia na poda)\n",
    "            'criterion': np.random.choice(['gini', 'entropy']),  # Critério aleatório\n",
    "            'ccp_alpha': np.random.uniform(0.0, 0.1)   # Parâmetro de complexidade de poda entre 0 e 0.05 (influencia na poda)\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=dt_iteration['parameters']['max_depth'], min_samples_split=dt_iteration['parameters']['min_samples_split'], criterion=dt_iteration['parameters']['criterion'], ccp_alpha=dt_iteration['parameters']['ccp_alpha'])\n",
    "    update_results(validation_results,'dt',dt_iteration,y_val,dt_clf)\n",
    "\n",
    "    ### SVM Classifier\n",
    "    svm_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'C': np.random.uniform(0.1, 1.0),  # Valor de erro aleatório (C)\n",
    "            'kernel': np.random.choice(['rbf', 'poly'])  # Tipo de Kernel aleatório (linear excluido por ser mais demorado)\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    svm_clf = SVC(C=svm_iteration['parameters']['C'], kernel=svm_iteration['parameters']['kernel'])\n",
    "    update_results(validation_results,'svm',svm_iteration,y_val,svm_clf) \n",
    "\n",
    "    ### MLP Classifier\n",
    "    mlp_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':{\n",
    "            'epochs': np.random.randint(100, 301),  # Número de épocas aleatório entre 100 e 300\n",
    "            'learning_rate': np.random.uniform(0.001, 0.1),  # Taxa de aprendizagem aleatória\n",
    "            'hidden_layers': np.random.randint(1, 6),  # Número de camadas escondidas aleatório entre 1 e 5\n",
    "            'activation': np.random.choice(['identity', 'logistic', 'tanh', 'relu']),  # Função de ativação aleatória\n",
    "            'tol': 1e-2  # Tolerância um pouco maior para convergência\n",
    "        },\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(mlp_iteration['parameters']['hidden_layers'],), max_iter=mlp_iteration['parameters']['epochs'], learning_rate_init=mlp_iteration['parameters']['learning_rate'], activation=mlp_iteration['parameters']['activation'], tol=mlp_iteration['parameters']['tol'])\n",
    "    update_results(validation_results,'mlp',mlp_iteration,y_val,mlp_clf) \n",
    "\n",
    "    validation_results['iterations'] += 1\n",
    "\n",
    "validation_results['elapsed_time'] = time.time() - validation_results['start_time']\n",
    "\n",
    "show_title(\"loop de validacao concluido\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10d68481-3275-4a5b-9f67-1f660fa4f2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>mostrar json ? (descomente)<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Exibir resultados de validação\u001b[39;00m\n\u001b[0;32m      2\u001b[0m show_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmostrar json ? (descomente)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(validation_results, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Exibir resultados de validação\n",
    "show_title(\"mostrar json ? (descomente)\")\n",
    "print(json.dumps(validation_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fc59124-63a3-49b0-a11c-085fe725f32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Medias de acuracias na validação<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.814953 0.861682 0.844860 0.755140\n",
      "1          2 0.813084 0.837383 0.859813 0.364486\n",
      "2          3 0.835514 0.833645 0.857944 0.755140\n",
      "3          4 0.841121 0.833645 0.846729 0.755140\n",
      "4          5 0.809346 0.863551 0.859813 0.857944\n",
      "5          6 0.809346 0.829907 0.844860 0.755140\n",
      "6          7 0.835514 0.833645 0.837383 0.755140\n",
      "7          8 0.842991 0.863551 0.856075 0.755140\n",
      "8          9 0.828037 0.829907 0.813084 0.803738\n",
      "9         10 0.835514 0.833645 0.846729 0.867290\n",
      "10       AVG 0.826542 0.842056 0.846729 0.742430\n",
      "11     WORST 0.809346 0.829907 0.813084 0.364486\n",
      "12      BEST 0.842991 0.863551 0.859813 0.867290\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Medias de tempos na validação<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.089664 0.019858 0.136833 0.056649\n",
      "1          2 0.149601 0.025930 0.139627 0.108709\n",
      "2          3 0.145617 0.020938 0.100244 0.041887\n",
      "3          4 0.088290 0.024112 0.078858 0.057775\n",
      "4          5 0.138630 0.019946 0.103723 0.149601\n",
      "5          6 0.152592 0.025931 0.079302 0.060705\n",
      "6          7 0.153589 0.021941 0.063831 0.110703\n",
      "7          8 0.086768 0.019947 0.120677 0.053856\n",
      "8          9 0.132846 0.022939 0.109225 0.103167\n",
      "9         10 0.138144 0.020104 0.104331 0.142132\n",
      "10       AVG 0.127574 0.022165 0.103665 0.088518\n",
      "11     WORST 0.153589 0.025931 0.139627 0.149601\n",
      "12      BEST 0.086768 0.019858 0.063831 0.041887\n"
     ]
    }
   ],
   "source": [
    "#tabulação dos resultados da validação e calculo das medias\n",
    "\n",
    "validation_accuracy_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "validation_time_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "validation_accuracy_avgs = {}\n",
    "validation_time_avgs = {}\n",
    "\n",
    "for alg in algoritms:\n",
    "    validation_accuracy_table[alg] = []\n",
    "    validation_accuracy_avgs[alg] = 0\n",
    "    validation_time_table[alg] = []\n",
    "    validation_time_avgs[alg] = 0\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    validation_accuracy_table['repetição'].append(i+1)  \n",
    "    validation_time_table['repetição'].append(i+1)  \n",
    "    for alg in algoritms:\n",
    "        if len(validation_results[alg]['iterations']) > 0:\n",
    "            validation_accuracy_table[alg].append(validation_results[alg]['iterations'][i]['accuracy'])\n",
    "            validation_accuracy_avgs[alg] += validation_results[alg]['iterations'][i]['accuracy']\n",
    "            validation_time_table[alg].append(validation_results[alg]['iterations'][i]['elapsed_time'])\n",
    "            validation_time_avgs[alg] += validation_results[alg]['iterations'][i]['elapsed_time']\n",
    "        else:\n",
    "            validation_accuracy_table[alg].append(0)\n",
    "            validation_time_table[alg].append(float('inf'))\n",
    "\n",
    "validation_accuracy_table['repetição'].append('AVG')\n",
    "validation_accuracy_table['repetição'].append('WORST')\n",
    "validation_accuracy_table['repetição'].append('BEST')\n",
    "validation_time_table['repetição'].append('AVG')\n",
    "validation_time_table['repetição'].append('WORST')\n",
    "validation_time_table['repetição'].append('BEST')\n",
    "for alg in algoritms:\n",
    "    validation_accuracy_avgs[alg] = validation_accuracy_avgs[alg] / iterations_count\n",
    "    validation_time_avgs[alg] = validation_time_avgs[alg] / iterations_count\n",
    "    validation_accuracy_table[alg].append(validation_accuracy_avgs[alg])\n",
    "    validation_accuracy_table[alg].append(validation_results[alg]['worst_accuracy']['accuracy'])\n",
    "    validation_accuracy_table[alg].append(validation_results[alg]['best_accuracy']['accuracy'])\n",
    "    validation_time_table[alg].append(validation_time_avgs[alg])\n",
    "    validation_time_table[alg].append(validation_results[alg]['worst_time']['elapsed_time'])\n",
    "    validation_time_table[alg].append(validation_results[alg]['best_time']['elapsed_time'])\n",
    "\n",
    "validation_accuracy_table = pd.DataFrame(validation_accuracy_table)\n",
    "validation_time_table = pd.DataFrame(validation_time_table)\n",
    "\n",
    "print()\n",
    "show_title(\"Medias de acuracias na validação\")\n",
    "print(validation_accuracy_table)\n",
    "#mostrar_dataframe_interativo(validation_accuracy_table,min(len(validation_accuracy_table),iterations_count)+1,min(len(validation_accuracy_table),iterations_count)+1)\n",
    "print()\n",
    "show_title(\"Medias de tempos na validação\")\n",
    "print(validation_time_table)\n",
    "#mostrar_dataframe_interativo(validation_time_table,min(len(validation_time_table),iterations_count)+1,min(len(validation_time_table),iterations_count)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03b474e5-d276-4b01-8039-2bc9a685f615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>loop de testes concluido<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOOP DE EXECUSSÕES DE TESTE (LOOP 2)\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    \n",
    "    ### KNN Classifier\n",
    "    knn_iteration = {        \n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['knn']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=knn_iteration['parameters']['k'], weights=knn_iteration['parameters']['weights'])\n",
    "    update_results(test_results,'knn',knn_iteration,y_val,knn_clf)\n",
    "    \n",
    "    ### Decision Tree Classifier\n",
    "    dt_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['dt']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=dt_iteration['parameters']['max_depth'], min_samples_split=dt_iteration['parameters']['min_samples_split'], criterion=dt_iteration['parameters']['criterion'], ccp_alpha=dt_iteration['parameters']['ccp_alpha'])\n",
    "    update_results(test_results,'dt',dt_iteration,y_val,dt_clf)\n",
    "\n",
    "    ### SVM Classifier\n",
    "    svm_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['svm']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    svm_clf = SVC(C=svm_iteration['parameters']['C'], kernel=svm_iteration['parameters']['kernel'])\n",
    "    update_results(test_results,'svm',svm_iteration,y_val,svm_clf)\n",
    "\n",
    "    ### MLP Classifier\n",
    "    mlp_iteration = {\n",
    "        'iteration':i,        \n",
    "        'parameters':validation_results['mlp']['best_accuracy']['parameters'],\n",
    "        'start_time': time.time()\n",
    "    }\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(mlp_iteration['parameters']['hidden_layers'],), max_iter=mlp_iteration['parameters']['epochs'], learning_rate_init=mlp_iteration['parameters']['learning_rate'], activation=mlp_iteration['parameters']['activation'],tol=mlp_iteration['parameters']['tol'])\n",
    "    update_results(test_results,'mlp',mlp_iteration,y_val,mlp_clf) \n",
    "\n",
    "    test_results['iterations'] += 1\n",
    "\n",
    "test_results['elapsed_time'] = time.time() - test_results['start_time']\n",
    "\n",
    "show_title(\"loop de testes concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51193a53-d49b-4750-8704-524aa91fa32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>mostrar json ? (descomente)<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Exibir resultados de teste\u001b[39;00m\n\u001b[0;32m      2\u001b[0m show_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmostrar json ? (descomente)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(test_results, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Exibir resultados de teste\n",
    "show_title(\"mostrar json ? (descomente)\")\n",
    "print(json.dumps(test_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52b1fa07-f85c-439d-a61e-06902128180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Medias de acuracias no teste<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 0.842991 0.863551 0.859813 0.816822\n",
      "1          2 0.842991 0.863551 0.859813 0.788785\n",
      "2          3 0.842991 0.863551 0.859813 0.803738\n",
      "3          4 0.842991 0.863551 0.859813 0.766355\n",
      "4          5 0.842991 0.863551 0.859813 0.807477\n",
      "5          6 0.842991 0.863551 0.859813 0.622430\n",
      "6          7 0.842991 0.863551 0.859813 0.871028\n",
      "7          8 0.842991 0.863551 0.859813 0.803738\n",
      "8          9 0.842991 0.863551 0.859813 0.796262\n",
      "9         10 0.842991 0.863551 0.859813 0.809346\n",
      "10       AVG 0.842991 0.863551 0.859813 0.788598\n",
      "11     WORST 0.842991 0.863551 0.859813 0.622430\n",
      "12      BEST 0.842991 0.863551 0.859813 0.871028\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Medias de tempos no teste<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repetição      knn       dt      svm      mlp\n",
      "0          1 3.835701 0.024827 0.161568 0.169650\n",
      "1          2 3.257056 0.024950 0.143539 0.182474\n",
      "2          3 3.919680 0.024933 0.190064 0.202847\n",
      "3          4 2.755792 0.024716 0.185971 0.176809\n",
      "4          5 2.172762 0.024836 0.145610 0.264877\n",
      "5          6 0.708420 0.025882 0.153456 0.194015\n",
      "6          7 0.199360 0.025931 0.145853 0.120105\n",
      "7          8 0.101235 0.024934 0.138630 0.215467\n",
      "8          9 0.095397 0.022487 0.123986 0.215419\n",
      "9         10 0.094747 0.024933 0.130024 0.257743\n",
      "10       AVG 1.714015 0.024843 0.151870 0.199941\n",
      "11     WORST 3.919680 0.025931 0.190064 0.264877\n",
      "12      BEST 0.094747 0.022487 0.123986 0.120105\n"
     ]
    }
   ],
   "source": [
    "#tabulação dos resultados da testes e calculo das medias\n",
    "\n",
    "test_accuracy_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "test_time_table = {\n",
    "    'repetição':[]\n",
    "}\n",
    "test_accuracy_avgs = {}\n",
    "test_time_avgs = {}\n",
    "\n",
    "for alg in algoritms:\n",
    "    test_accuracy_table[alg] = []\n",
    "    test_accuracy_avgs[alg] = 0\n",
    "    test_time_table[alg] = []\n",
    "    test_time_avgs[alg] = 0\n",
    "\n",
    "for i in range(iterations_count):\n",
    "    test_accuracy_table['repetição'].append(i+1)  \n",
    "    test_time_table['repetição'].append(i+1)  \n",
    "    for alg in algoritms:\n",
    "        if len(test_results[alg]['iterations']) > 0:\n",
    "            test_accuracy_table[alg].append(test_results[alg]['iterations'][i]['accuracy'])\n",
    "            test_accuracy_avgs[alg] += test_results[alg]['iterations'][i]['accuracy']\n",
    "            test_time_table[alg].append(test_results[alg]['iterations'][i]['elapsed_time'])\n",
    "            test_time_avgs[alg] += test_results[alg]['iterations'][i]['elapsed_time']\n",
    "        else:\n",
    "            test_accuracy_table[alg].append(0)\n",
    "            test_time_table[alg].append(float('inf'))\n",
    "\n",
    "test_accuracy_table['repetição'].append('AVG')\n",
    "test_accuracy_table['repetição'].append('WORST')\n",
    "test_accuracy_table['repetição'].append('BEST')\n",
    "test_time_table['repetição'].append('AVG')\n",
    "test_time_table['repetição'].append('WORST')\n",
    "test_time_table['repetição'].append('BEST')\n",
    "for alg in algoritms:\n",
    "    test_accuracy_avgs[alg] = test_accuracy_avgs[alg] / iterations_count\n",
    "    test_time_avgs[alg] = test_time_avgs[alg] / iterations_count\n",
    "    test_accuracy_table[alg].append(test_accuracy_avgs[alg])\n",
    "    test_accuracy_table[alg].append(test_results[alg]['worst_accuracy']['accuracy'])\n",
    "    test_accuracy_table[alg].append(test_results[alg]['best_accuracy']['accuracy'])\n",
    "    test_time_table[alg].append(test_time_avgs[alg])\n",
    "    test_time_table[alg].append(test_results[alg]['worst_time']['elapsed_time'])\n",
    "    test_time_table[alg].append(test_results[alg]['best_time']['elapsed_time'])\n",
    "\n",
    "test_accuracy_table = pd.DataFrame(test_accuracy_table)\n",
    "test_time_table = pd.DataFrame(test_time_table)\n",
    "\n",
    "print()\n",
    "show_title(\"Medias de acuracias no teste\")\n",
    "print(test_accuracy_table)\n",
    "#mostrar_dataframe_interativo(test_accuracy_table,min(len(test_accuracy_table),iterations_count)+1,min(len(test_accuracy_table),iterations_count)+1)\n",
    "print()\n",
    "show_title(\"Medias de tempos no teste\")\n",
    "print(test_time_table)\n",
    "#mostrar_dataframe_interativo(test_time_table,min(len(test_time_table),iterations_count)+1,min(len(test_time_table),iterations_count)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "511ff826-0933-4cd4-8223-7a7180435b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>Resultado do teste de Kruskal-Wallis:<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatística: 13.776174306734594\n",
      "p-valor: 0.003226203916811015\n",
      "Isso indica que os valores das acuracias apuradas são significativamente diferentes.\n"
     ]
    }
   ],
   "source": [
    "#Aplicando estatistica de Kruskal-Wallis\n",
    "df_statics = validation_accuracy_table.iloc[:-3] #elimina as 3 ultimas linhas, que contem as medias, melhores e piores\n",
    "\n",
    "kruskal_result = kruskal(df_statics['knn'], df_statics['dt'], df_statics['svm'], df_statics['mlp'])\n",
    "show_title(\"Resultado do teste de Kruskal-Wallis:\")\n",
    "print(\"Estatística:\", kruskal_result.statistic)\n",
    "print(\"p-valor:\", kruskal_result.pvalue)\n",
    "\n",
    "alpha = 0.05\n",
    "if kruskal_result.pvalue < alpha:\n",
    "    print('Isso indica que os valores das acuracias apuradas são significativamente diferentes.')\n",
    "else:\n",
    "    print('Isso indica que os valores das acuracias apuradas não são significativamente diferentes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c5666c4-bf72-4aa9-9d43-c35be0f1cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style='font-family:Courier New;text-align: center; color: lawngreen;font-weight:bolder;'>\n",
       "Teste de Mann-Whitney (comparação dois a dois):<h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparação MLP vs DT:\n",
      "  Estatística: 17.0\n",
      "  p-valor: 0.01237160821796184\n",
      "  Isso indica que os valores das acuracias apuradas são significativamente diferentes.\n",
      "Comparação MLP vs SVM:\n",
      "  Estatística: 17.5\n",
      "  p-valor: 0.014079121613493622\n",
      "  Isso indica que os valores das acuracias apuradas são significativamente diferentes.\n",
      "Comparação MLP vs KNN:\n",
      "  Estatística: 20.0\n",
      "  p-valor: 0.0235556726630649\n",
      "  Isso indica que os valores das acuracias apuradas são significativamente diferentes.\n",
      "Comparação DT vs SVM:\n",
      "  Estatística: 37.5\n",
      "  p-valor: 0.3614420145078252\n",
      "  Isso indica que os valores das acuracias apuradas não são significativamente diferentes.\n",
      "Comparação DT vs KNN:\n",
      "  Estatística: 68.0\n",
      "  p-valor: 0.18305346808287726\n",
      "  Isso indica que os valores das acuracias apuradas não são significativamente diferentes.\n",
      "Comparação SVM vs KNN:\n",
      "  Estatística: 90.5\n",
      "  p-valor: 0.0024133553534221547\n",
      "  Isso indica que os valores das acuracias apuradas são significativamente diferentes.\n"
     ]
    }
   ],
   "source": [
    "# # Comparação par-a-par com Mann-Whitney\n",
    "\n",
    "show_title(\"\\nTeste de Mann-Whitney (comparação dois a dois):\")\n",
    "classifiers = {\n",
    "    'MLP': df_statics['mlp'],\n",
    "    'DT': df_statics['dt'],\n",
    "    'SVM': df_statics['svm'],\n",
    "    'KNN': df_statics['knn']\n",
    "}\n",
    "alpha = 0.05\n",
    "\n",
    "for (name1, acc1), (name2, acc2) in itertools.combinations(classifiers.items(), 2):\n",
    "    mannwhitney_result = mannwhitneyu(acc1, acc2, alternative='two-sided')\n",
    "    print(f\"Comparação {name1} vs {name2}:\")\n",
    "    print(\"  Estatística:\", mannwhitney_result.statistic)\n",
    "    print(\"  p-valor:\", mannwhitney_result.pvalue)\n",
    "    if mannwhitney_result.pvalue < alpha:\n",
    "        print('  Isso indica que os valores das acuracias apuradas são significativamente diferentes.')\n",
    "    else:\n",
    "        print('  Isso indica que os valores das acuracias apuradas não são significativamente diferentes.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52599e-4da0-4433-8631-8558701090f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
